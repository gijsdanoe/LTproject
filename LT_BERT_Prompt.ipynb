{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prompt with Bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke0wvVTABQ5t"
      },
      "outputs": [],
      "source": [
        "!pip install openprompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys\n",
        "import csv\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments,Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/frame')"
      ],
      "metadata": {
        "id": "Rff0fnXRB8Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "train_arguments = []\n",
        "train_frames = []\n",
        "train_topics = []\n",
        "with open('/content/drive/MyDrive/frame/Final data/Train.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        train_arguments.append(row[2])\n",
        "        train_frames.append(row[-1])\n",
        "        train_topics.append(row[4])\n",
        "\n",
        "val_arguments = []\n",
        "val_frames = []\n",
        "val_topics = []\n",
        "with open('/content/drive/MyDrive/frame/Final data/Validation.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        val_arguments.append(row[2])\n",
        "        val_frames.append(row[-1])\n",
        "        val_topics.append(row[4])\n",
        "\n",
        "test_arguments = []\n",
        "test_frames = []\n",
        "test_topics = []\n",
        "with open('/content/drive/MyDrive/frame/Final data/Test.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        test_arguments.append(row[2])\n",
        "        test_frames.append(row[-1])\n",
        "        test_topics.append(row[4])"
      ],
      "metadata": {
        "id": "sdKGuJTDB_kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional REMOVE IMPORTANT FEATURES PER TOPIC\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(train_arguments)\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_topics)\n",
        "Y = le.transform(train_topics)\n",
        "\n",
        "clf = SGDClassifier(loss='log')\n",
        "clf.fit(X, Y)\n",
        "\n",
        "labeldict = defaultdict(list)\n",
        "for i in range(0, clf.coef_.shape[0]):\n",
        "    top20_indices = np.argsort(clf.coef_[i])[-50:]\n",
        "    for j in top20_indices:\n",
        "      labeldict[le.classes_[i]].append(vectorizer.get_feature_names()[j])\n",
        "\n",
        "train = list(zip(train_arguments, train_topics))\n",
        "val = list(zip(val_arguments, val_topics))\n",
        "test = list(zip(test_arguments, test_topics))\n",
        "\n",
        "train_arguments = []\n",
        "for i in train:\n",
        "  sent = i[0].split()\n",
        "  for word in sent:\n",
        "    if word in labeldict[i[1]]:\n",
        "      sent[sent.index(word)] = '[MASK]'\n",
        "  train_arguments.append(' '.join(sent))\n",
        "\n",
        "val_arguments = []\n",
        "for i in val:\n",
        "  sent = i[0].split()\n",
        "  for word in sent:\n",
        "    if word in labeldict[i[1]]:\n",
        "      sent[sent.index(word)] = '[MASK]'\n",
        "  val_arguments.append(' '.join(sent))\n",
        "\n",
        "test_arguments = []\n",
        "for i in test:\n",
        "  sent = i[0].split()\n",
        "  for word in sent:\n",
        "    if word in labeldict[i[1]]:\n",
        "      sent[sent.index(word)] = '[MASK]'\n",
        "  test_arguments.append(' '.join(sent))"
      ],
      "metadata": {
        "id": "XQBsen__CC3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to numbers\n",
        "labeldict = {'Morality':0,'Quality of Life':1,'Crime and punishment':2,'International relations and reputation':3,'Fairness and equality':4,'Cultural identity':5,'Political':6,'Capacity and resources':7,'Security and defense':8,'Health and Safety':9,'Economic':10,'Climate and environment':11,'Historical':12,'Policy prescription and evaluation':13,'Education':14,'Technology and innovation':15,'Legality, constitutionality and jurisprudence':16,'Public opinion':17, 'Irrelevant':18, 'Other':19}\n",
        "train_frames_bin = []\n",
        "val_frames_bin = []\n",
        "test_frames_bin = []\n",
        "for label in train_frames:\n",
        "    train_frames_bin.append(labeldict[label])\n",
        "for label in val_frames:\n",
        "    val_frames_bin.append(labeldict[label])\n",
        "for label in test_frames:\n",
        "    test_frames_bin.append(labeldict[label])"
      ],
      "metadata": {
        "id": "2S7s2TOUCJEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine classes \n",
        "from openprompt.data_utils import InputExample\n",
        "input_train = []\n",
        "for x in range(len(train_arguments)):\n",
        "  example = InputExample(guid = x, text_a=train_arguments[x], label=train_frames_bin[x])\n",
        "  input_train.append(example)\n",
        "\n",
        "input_test = []\n",
        "for x in range(len(test_arguments)):\n",
        "  example = InputExample(guid = x, text_a=test_arguments[x], label=test_frames_bin[x])\n",
        "  input_test.append(example)\n",
        "\n",
        "input_val = []\n",
        "for x in range(len(val_arguments)):\n",
        "  example = InputExample(guid = x, text_a=val_arguments[x], label=val_frames_bin[x])\n",
        "  input_val.append(example)\n",
        "\n",
        "from openprompt.data_utils import InputExample\n",
        "classes = [ # 18 categories including irrelevant and other\n",
        "\"capacity and resources\", \n",
        "\"climate and environment\",\n",
        "\"crime and punishment\",\n",
        "\"cultural identity\",\n",
        "\"economic\",\n",
        "\"education\",\n",
        "\"fairness and equality\",\n",
        "\"health and safety\",\n",
        "\"historical\",\n",
        "\"international relations and reputation\",\n",
        "\"irrelevant\",\n",
        "\"legality constitutionality and jurisprudence\",\n",
        "\"morality\",\n",
        "\"other\",\n",
        "\"policy prescription and evaluation\",\n",
        "\"political\",\n",
        "\"public opinion\",\n",
        "\"quality of life\",\n",
        "\"security and defense\",\n",
        "\"technology and innovation\"\n",
        "]"
      ],
      "metadata": {
        "id": "fGCn8U-DCR8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT pre-trained language model\n",
        "from openprompt.plms import load_plm\n",
        "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-cased\")"
      ],
      "metadata": {
        "id": "AVYD7PQjCUJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct templates\n",
        "from openprompt.prompts import ManualTemplate\n",
        "promptTemplate = ManualTemplate(\n",
        "    text = '{\"placeholder\":\"text_a\"} The frame of {\"placeholder\":\"text_a\"} is {\"mask\"}',\n",
        "    tokenizer = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "VG8bY2m4CW7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the verbalizer\n",
        "from openprompt.prompts import ManualVerbalizer\n",
        "promptVerbalizer = ManualVerbalizer(\n",
        "    classes = classes,\n",
        "    label_words = { #18 categories\n",
        "        \"capacity and resources\": [\"knowledge\"], \n",
        "\"climate and environment\": [\"climate\"], \n",
        "\"crime and punishment\": [\"crime\"], \n",
        "\"cultural identity\": [\"minority\"],\n",
        "\"economic\": [\"tax\"],\n",
        "\"education\": [\"school\"],\n",
        "\"fairness and equality\": [\"sex\", \"gender\"], \n",
        "\"health and safety\": [\"food\"],\n",
        "\"historical\": [\"history\"],\n",
        "\"international relations and reputation\": [\"country\"],\n",
        "\"irrelevant\": [\"irrelevant\"],\n",
        "\"legality constitutionality and jurisprudence\": [\"law\"],\n",
        "\"morality\": [\"moral\"] ,\n",
        "\"other\": [\"other\"],\n",
        "\"policy prescription and evaluation\": [\"policy\"],\n",
        "\"political\": [\"political\"] ,\n",
        "\"public opinion\": [\"publicity\"],\n",
        "\"quality of life\": [\"quality\"],\n",
        "\"security and defense\": [\"safe\"],\n",
        "\"technology and innovation\": [\"technology\"],\n",
        "    },\n",
        "    tokenizer = tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "MdZnow9uCZhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "\n",
        "# Combine PLM, template and verbalizer into a prompt model\n",
        "from openprompt import PromptForClassification\n",
        "promptModel = PromptForClassification(\n",
        "    template = promptTemplate,\n",
        "    plm = plm,\n",
        "    verbalizer = promptVerbalizer,\n",
        ")\n",
        "if use_cuda:\n",
        "    promptModel=  promptModel.cuda()"
      ],
      "metadata": {
        "id": "v9BggAgXCc7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a dataloader\n",
        "from openprompt import PromptDataLoader\n",
        "data_loader_train = PromptDataLoader(dataset = input_train, \n",
        "        tokenizer = tokenizer,\n",
        "        template = promptTemplate, \n",
        "        tokenizer_wrapper_class=WrapperClass,\n",
        ")"
      ],
      "metadata": {
        "id": "B3_nZs4JCfx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Pytorch to train the data\n",
        "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "# it's always good practice to set no decay to biase and LayerNorm parameters\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in promptModel.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in promptModel.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "\n",
        "for epoch in range(25):\n",
        "    tot_loss = 0\n",
        "    for step, inputs in enumerate(data_loader_train):\n",
        "        if use_cuda:\n",
        "            inputs = inputs.cuda()\n",
        "        logits = promptModel(inputs)\n",
        "        labels = inputs['label']\n",
        "        loss = loss_func(logits, labels)\n",
        "        loss.backward()\n",
        "        tot_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if step %100 ==1:\n",
        "            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n"
      ],
      "metadata": {
        "id": "60Nmtq_ECkIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate \n",
        "data_loader_val = PromptDataLoader(dataset = input_test, \n",
        "        tokenizer = tokenizer,\n",
        "        template = promptTemplate, \n",
        "        tokenizer_wrapper_class=WrapperClass, max_seq_length=256, decoder_max_length=3,\n",
        "    batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
        "    truncate_method=\"head\")\n",
        "\n",
        "allpreds = []\n",
        "alllabels = []\n",
        "for step, inputs in enumerate(data_loader_val):\n",
        "    if use_cuda:\n",
        "        inputs = inputs.cuda()\n",
        "    logits = promptModel(inputs)\n",
        "    labels = inputs['label']\n",
        "    alllabels.extend(labels.cpu().tolist())\n",
        "    allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
        "\n",
        "acc = sum([int(i==j) for i,j in zip(allpreds, alllabels)])/len(allpreds)\n",
        "print(acc)\n",
        "print(classification_report(alllabels, allpreds, zero_division=True, digits=3))"
      ],
      "metadata": {
        "id": "nIxAdFs4CysV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}